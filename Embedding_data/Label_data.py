import psycopg2
import os
import json
import requests
from typing import Dict, List, Optional, Union, Any
from dataclasses import dataclass, asdict
from enum import Enum
import base64
from io import BytesIO
from PIL import Image
import google.generativeai as genai
from datetime import datetime, timedelta
import uuid
import numpy as np
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
import time
from embedding_service import EmbeddingService
import ollama


# Configuration
class ModelProvider(Enum):
    OLLAMA = "ollama"
    GOOGLE = "google"
    BOTH = "both"


@dataclass
class ProductLabel:
    """Cáº¥u trÃºc label sáº£n pháº©m theo file PDF"""
    image_url: str
    image_recipient: List[str]
    target_audience: List[str]
    usage_purpose: List[str]
    occasion: List[str]
    niche_theme: List[str]
    sentiment_tone: List[str]
    message_type: List[str]
    personalization_type: List[str]
    product_type: List[str]
    placement_display_context: List[str]
    design_style: List[str]
    color_aesthetic: List[str]
    trademark_level: str
    main_subject: List[str]
    text: List[str]


@dataclass
class ProductRecord:
    """Cáº¥u trÃºc record Ä‘á»ƒ insert vÃ o Milvus"""
    id_sanpham: str
    image: str
    date: str
    like: str
    comment: str
    share: str
    link_redirect: str
    platform: str
    name_store: str
    description: str
    metadata: dict
    image_vector: List[float]
    description_vector: List[float]


class IntegratedProductPipeline:
    """Module tÃ­ch há»£p: Crawl Data â†’ Label â†’ Insert Milvus vá»›i GPT OSS 20B"""

    def __init__(self,
                 db_config: Dict[str, str],
                 google_api_key: str,
                 ollama_model: str = "gpt-oss:20b",
                 milvus_host: str = "10.10.4.25",
                 milvus_port: str = "19530",
                 use_gpu: bool = True):
        """
        Khá»Ÿi táº¡o pipeline tÃ­ch há»£p vá»›i GPT OSS 20B vÃ  GPU support

        Args:
            db_config: Cáº¥u hÃ¬nh database PostgreSQL
            google_api_key: API key cho Google Gemini
            ollama_model: Model Ollama Ä‘á»ƒ sá»­ dá»¥ng (máº·c Ä‘á»‹nh: gpt-oss:20b)
            milvus_host: Milvus host
            milvus_port: Milvus port
            use_gpu: Sá»­ dá»¥ng GPU hay khÃ´ng
        """
        # Database config
        self.db_config = db_config
        self.db_connection = None
        
        # GPU config
        self.use_gpu = use_gpu
        self._setup_gpu_environment()

        # AI Labeler - Updated for GPT OSS 20B
        self.ollama_model = ollama_model
        self.google_client = None

        # Kiá»ƒm tra vÃ  verify model availability
        self._verify_ollama_model()

        # Khá»Ÿi táº¡o EmbeddingService vá»›i GPU support
        print("ğŸ”§ Khá»Ÿi táº¡o Embedding Service vá»›i GPU support...")
        self.embedding_service = EmbeddingService()
        self.embedding_dim = self.embedding_service.embedding_dim

        # Khá»Ÿi táº¡o Google Gemini
        if google_api_key:
            genai.configure(api_key=google_api_key)
            self.google_client = genai.GenerativeModel('gemini-1.5-pro-latest')

        # Milvus config
        self.milvus_host = milvus_host
        self.milvus_port = milvus_port
        self.collection_name = "product_collection"
        self.collection = None

        # Log model info
        model_info = self.embedding_service.get_model_info()
        print(f"ğŸ¤– Embedding Model: {model_info['model_name']}")
        print(f"ğŸ“Š Embedding Dimensions: {model_info['embedding_dimension']}")
        print(f"ğŸ”§ Device: {model_info['device']}")
        print(f"ğŸ¦¾ Ollama Model: {self.ollama_model}")

        # Initialize connections
        self._connect_db()
        self._connect_milvus()
        self._setup_collection()

    def _setup_gpu_environment(self):
        """Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng GPU"""
        if self.use_gpu:
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_count = torch.cuda.device_count()
                    gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else "Unknown"
                    print(f"ğŸš€ GPU Support: Enabled")
                    print(f"   ğŸ”¥ Device: {gpu_name}")
                    print(f"   ğŸ“Š GPU Count: {gpu_count}")
                    print(f"   ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
                    
                    # Set GPU environment variables cho Ollama
                    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
                    os.environ['OLLAMA_GPU'] = '1'
                else:
                    print("âš ï¸  CUDA khÃ´ng kháº£ dá»¥ng, sá»­ dá»¥ng CPU")
                    self.use_gpu = False
            except ImportError:
                print("âš ï¸  PyTorch khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t, sá»­ dá»¥ng CPU")
                self.use_gpu = False
        else:
            print("ğŸ–¥ï¸  GPU Support: Disabled (sá»­ dá»¥ng CPU)")

    def _verify_ollama_model(self):
        """Kiá»ƒm tra vÃ  verify model Ollama cÃ³ sáºµn - Fixed version"""
        try:
            print(f"ğŸ” Kiá»ƒm tra model {self.ollama_model}...")
            
            # List available models vá»›i error handling tá»‘t hÆ¡n
            try:
                available_models = ollama.list()
                print(f"ğŸ“‹ Raw response structure: {type(available_models)}")
                
                # Handle different response structures
                if isinstance(available_models, dict):
                    if 'models' in available_models:
                        model_list = available_models['models']
                    else:
                        model_list = available_models
                else:
                    model_list = available_models
                
                # Extract model names safely
                model_names = []
                if isinstance(model_list, list):
                    for model in model_list:
                        if isinstance(model, dict):
                            # Try different possible keys
                            name = model.get('name') or model.get('model') or model.get('id', 'unknown')
                            model_names.append(name)
                        else:
                            model_names.append(str(model))
                
                print(f"ğŸ“‹ Available models: {model_names}")
                
            except Exception as e:
                print(f"âš ï¸  Lá»—i list models: {str(e)}")
                print(f"ğŸ’¡ Thá»­ pull model trá»±c tiáº¿p...")
                model_names = []
            
            # Check if our model is available
            if self.ollama_model not in model_names:
                print(f"âš ï¸  Model {self.ollama_model} chÆ°a cÃ³ sáºµn!")
                print(f"ğŸ”„ Äang tá»± Ä‘á»™ng pull model {self.ollama_model}...")
                
                try:
                    # Pull model vá»›i progress tracking
                    print("â³ Pulling model... (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)")
                    ollama.pull(self.ollama_model)
                    print(f"âœ… ÄÃ£ pull model {self.ollama_model} thÃ nh cÃ´ng!")
                    
                    # Verify model is working
                    test_response = ollama.generate(
                        model=self.ollama_model,
                        prompt="Test message",
                        options={'num_predict': 10}
                    )
                    print(f"âœ… Model {self.ollama_model} Ä‘Ã£ sáºµn sÃ ng vÃ  hoáº¡t Ä‘á»™ng!")
                    
                except Exception as pull_error:
                    print(f"âŒ Lá»—i pull model: {str(pull_error)}")
                    print(f"ğŸ’¡ Vui lÃ²ng cháº¡y thá»§ cÃ´ng: ollama pull {self.ollama_model}")
                    raise Exception(f"Model {self.ollama_model} khÃ´ng kháº£ dá»¥ng")
            else:
                print(f"âœ… Model {self.ollama_model} Ä‘Ã£ sáºµn sÃ ng!")
                
                # Quick test
                try:
                    test_response = ollama.generate(
                        model=self.ollama_model,
                        prompt="Hello",
                        options={'num_predict': 5}
                    )
                    print(f"âœ… Model test successful!")
                except Exception as test_error:
                    print(f"âš ï¸  Model test warning: {str(test_error)}")
                
        except Exception as e:
            print(f"âŒ Lá»—i kiá»ƒm tra model: {str(e)}")
            print(f"ğŸ’¡ Vui lÃ²ng Ä‘áº£m báº£o:")
            print(f"   1. Ollama Ä‘ang cháº¡y: ollama serve")
            print(f"   2. Model Ä‘Ã£ Ä‘Æ°á»£c pull: ollama pull {self.ollama_model}")
            print(f"   3. CÃ³ Ä‘á»§ VRAM cho model (khoáº£ng 12-16GB)")

    def _connect_db(self) -> bool:
        """Káº¿t ná»‘i Ä‘áº¿n PostgreSQL database"""
        try:
            self.db_connection = psycopg2.connect(**self.db_config)
            print("âœ… Káº¿t ná»‘i PostgreSQL thÃ nh cÃ´ng")
            return True
        except Exception as e:
            print(f"âŒ Lá»—i káº¿t ná»‘i database: {e}")
            return False

    def _connect_milvus(self):
        """Káº¿t ná»‘i tá»›i Milvus"""
        try:
            connections.connect(
                alias="default",
                host=self.milvus_host,
                port=self.milvus_port
            )
            print("âœ… Káº¿t ná»‘i Milvus thÃ nh cÃ´ng")
        except Exception as e:
            raise Exception(f"âŒ Lá»—i káº¿t ná»‘i Milvus: {str(e)}")

    def _create_collection_schema(self):
        """Táº¡o schema cho collection vá»›i embedding dimensions Ä‘á»™ng"""
        fields = [
            FieldSchema(name="id_sanpham", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),
            FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=self.embedding_dim),
            FieldSchema(name="description_vector", dtype=DataType.FLOAT_VECTOR, dim=self.embedding_dim),
            FieldSchema(name="image", dtype=DataType.VARCHAR, max_length=1000),
            FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=5000),
            FieldSchema(name="metadata", dtype=DataType.JSON),
            FieldSchema(name="date", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="like", dtype=DataType.VARCHAR, max_length=20),
            FieldSchema(name="comment", dtype=DataType.VARCHAR, max_length=20),
            FieldSchema(name="share", dtype=DataType.VARCHAR, max_length=20),
            FieldSchema(name="link_redirect", dtype=DataType.VARCHAR, max_length=2000),
            FieldSchema(name="platform", dtype=DataType.VARCHAR, max_length=200),
            FieldSchema(name="name_store", dtype=DataType.VARCHAR, max_length=500)
        ]

        schema = CollectionSchema(
            fields=fields,
            description=f"Collection chá»©a thÃ´ng tin sáº£n pháº©m vá»›i embedding {self.embedding_dim}D"
        )
        return schema

    def _setup_collection(self):
        """Táº¡o hoáº·c load collection"""
        try:
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
                print(f"âœ… Load collection '{self.collection_name}' thÃ nh cÃ´ng")
            else:
                schema = self._create_collection_schema()
                self.collection = Collection(self.collection_name, schema)
                self._create_indexes()
                print(f"âœ… Táº¡o collection '{self.collection_name}' thÃ nh cÃ´ng vá»›i {self.embedding_dim}D vectors")

            self.collection.load()

        except Exception as e:
            raise Exception(f"âŒ Lá»—i setup collection: {str(e)}")

    def _create_indexes(self):
        """Táº¡o index cho vector fields"""
        # Chá»n nlist phÃ¹ há»£p vá»›i embedding dimension
        nlist = min(self.embedding_dim, 1024)

        index_params = {
            "metric_type": "COSINE",
            "index_type": "IVF_FLAT",
            "params": {"nlist": nlist}
        }

        self.collection.create_index(
            field_name="image_vector",
            index_params=index_params,
            index_name="image_vector_index"
        )

        self.collection.create_index(
            field_name="description_vector",
            index_params=index_params,
            index_name="description_vector_index"
        )
        print(f"âœ… Táº¡o indexes thÃ nh cÃ´ng vá»›i nlist={nlist}")

    # === DUPLICATE CHECK METHODS ===
    def check_id_exists(self, id_sanpham: str) -> bool:
        """
        Kiá»ƒm tra xem ID sáº£n pháº©m Ä‘Ã£ tá»“n táº¡i trong Milvus chÆ°a
        """
        try:
            expr = f'id_sanpham == "{id_sanpham}"'
            results = self.collection.query(
                expr=expr,
                output_fields=["id_sanpham"],
                limit=1
            )
            return len(results) > 0
        except Exception as e:
            print(f"âš ï¸  Lá»—i kiá»ƒm tra ID tá»“n táº¡i {id_sanpham}: {str(e)}")
            return False

    def check_ids_exist_batch(self, id_list: List[str]) -> Dict[str, bool]:
        """Kiá»ƒm tra nhiá»u ID cÃ¹ng lÃºc Ä‘á»ƒ tá»‘i Æ°u performance"""
        try:
            if not id_list:
                return {}

            id_conditions = [f'id_sanpham == "{id_val}"' for id_val in id_list]
            expr = " or ".join(id_conditions)

            results = self.collection.query(
                expr=expr,
                output_fields=["id_sanpham"],
                limit=len(id_list)
            )

            existing_ids = {result["id_sanpham"] for result in results}
            return {id_val: id_val in existing_ids for id_val in id_list}

        except Exception as e:
            print(f"âš ï¸  Lá»—i kiá»ƒm tra batch IDs: {str(e)}")
            return {id_val: False for id_val in id_list}

    def filter_existing_records(self, raw_data_list: List[Dict[str, Any]]) -> tuple:
        """Lá»c bá» cÃ¡c record Ä‘Ã£ tá»“n táº¡i trong Milvus"""
        try:
            if not raw_data_list:
                return [], [], 0

            print(f"ğŸ” Kiá»ƒm tra trÃ¹ng láº·p cho {len(raw_data_list)} records...")

            id_list = [record.get('id_sanpham', '') for record in raw_data_list if record.get('id_sanpham')]

            if not id_list:
                return raw_data_list, [], 0

            existence_map = self.check_ids_exist_batch(id_list)

            new_records = []
            existing_records = []

            for record in raw_data_list:
                id_sanpham = record.get('id_sanpham', '')
                if id_sanpham and existence_map.get(id_sanpham, False):
                    existing_records.append(record)
                else:
                    new_records.append(record)

            duplicate_count = len(existing_records)

            print(f"âœ… Káº¿t quáº£ kiá»ƒm tra trÃ¹ng láº·p:")
            print(f"   ğŸ“¦ Records má»›i: {len(new_records)}")
            print(f"   ğŸ”„ Records trÃ¹ng láº·p: {duplicate_count}")

            if duplicate_count > 0:
                print(f"   ğŸ“‹ Má»™t sá»‘ ID trÃ¹ng láº·p:")
                for i, record in enumerate(existing_records[:5]):
                    print(f"      {i + 1}. {record.get('id_sanpham', 'unknown')}")
                if duplicate_count > 5:
                    print(f"      ... vÃ  {duplicate_count - 5} ID khÃ¡c")

            return new_records, existing_records, duplicate_count

        except Exception as e:
            print(f"âŒ Lá»—i khi lá»c records trÃ¹ng láº·p: {str(e)}")
            return raw_data_list, [], 0

    # === CRAWL DATA METHODS ===
    def crawl_data_by_date_range(self, start_date: str, end_date: str, limit: int = 1000) -> List[Dict[str, Any]]:
        """Crawl data tá»« database theo khoáº£ng thá»i gian"""
        if not self.db_connection:
            if not self._connect_db():
                return []

        try:
            cursor = self.db_connection.cursor()

            query = """
            SELECT 
                COALESCE(_id, CONCAT('SP_', SUBSTRING(MD5(_id::text), 1, 8))) as id_sanpham,
                COALESCE(original_url, thumb_url, '') as image,
                COALESCE(CAST(created_at_std AS text), CAST(NOW() AS text)) as date,
                COALESCE(CAST("like" AS text), '0') as like,
                COALESCE(CAST(comment AS text), '0') as comment,
                COALESCE(CAST(share AS text), '0') as share,
                COALESCE(final_url, link, '') as link_redirect,
                COALESCE(platform, 'Website') as platform,
                COALESCE(domain, 'unknown') as name_store
            FROM ai_craw.toidispy_full
            WHERE created_at_std BETWEEN %s AND %s
            ORDER BY created_at_std DESC
            LIMIT %s
            """

            cursor.execute(query, (start_date, end_date, limit))
            columns = [desc[0] for desc in cursor.description]
            results = []

            for row in cursor.fetchall():
                row_dict = dict(zip(columns, row))
                results.append(row_dict)

            cursor.close()
            print(f"âœ… Crawl Ä‘Æ°á»£c {len(results)} records tá»« {start_date} Ä‘áº¿n {end_date}")
            return results

        except Exception as e:
            print(f"âŒ Lá»—i khi crawl data: {e}")
            return []
        

    # === LABELING METHODS - UPDATED FOR GPT OSS 20B ===
    def _create_labeling_prompt(self) -> str:
        """Táº¡o prompt chi tiáº¿t Ä‘Æ°á»£c tá»‘i Æ°u cho GPT OSS 20B"""
        return """
Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch sáº£n pháº©m vá»›i kháº£ nÄƒng hiá»ƒu sÃ¢u vá» thá»‹ trÆ°á»ng vÃ  xu hÆ°á»›ng ngÆ°á»i tiÃªu dÃ¹ng. HÃ£y phÃ¢n tÃ­ch hÃ¬nh áº£nh sáº£n pháº©m nÃ y vÃ  Ä‘Ã¡nh label theo cÃ¡c tiÃªu chÃ­ sau:

**QUAN TRá»ŒNG: CHá»ˆ CHá»ŒN 1-3 LABELS CHÃNH VÃ€ PHá»¦ Há»¢P NHáº¤T CHO Má»–I TIÃŠU CHÃ**

**HÆ¯á»šNG DáºªN PHÃ‚N TÃCH:**
- Quan sÃ¡t ká»¹ thiáº¿t káº¿, mÃ u sáº¯c, vÄƒn báº£n, vÃ  bá»‘i cáº£nh sá»­ dá»¥ng
- XÃ¡c Ä‘á»‹nh Ä‘á»‘i tÆ°á»£ng ngÆ°á»i dÃ¹ng chÃ­nh tá»« visual cues
- PhÃ¢n tÃ­ch cáº£m xÃºc vÃ  thÃ´ng Ä‘iá»‡p mÃ  sáº£n pháº©m truyá»n táº£i
- ChÃº Ã½ Ä‘áº¿n cháº¥t lÆ°á»£ng vÃ  phong cÃ¡ch thiáº¿t káº¿

**LÆ¯U Ã QUAN TRá»ŒNG:**
- Khi tháº¥y "Children", hÃ£y chi tiáº¿t hÃ³a thÃ nh "Son", "Daughter", "Kids" thay vÃ¬ dÃ¹ng "Children" chung chung
- "3D Rendered" chá»‰ Ã¡p dá»¥ng khi THIáº¾T Káº¾ BÃŠN TRONG sáº£n pháº©m cÃ³ váº» Ä‘Æ°á»£c táº¡o báº±ng 3D rendering, KHÃ”NG PHáº¢I vÃ¬ áº£nh mockup trÃ´ng 3D
- PhÃ¢n biá»‡t rÃµ rÃ ng giá»¯a mockup presentation vÃ  design style thá»±c táº¿ cá»§a sáº£n pháº©m
- Æ¯u tiÃªn Ä‘á»™ chÃ­nh xÃ¡c vÃ  cá»¥ thá»ƒ trong tá»«ng label

**TIÃŠU CHÃ ÄÃNH LABEL:**

1. **Image Recipient** (NgÆ°á»i nháº­n - MAX 4 labels chÃ­nh):
   - Thay vÃ¬ "Children" â†’ sá»­ dá»¥ng "Son", "Daughter", "Kids" cá»¥ thá»ƒ
   - Chá»n Ä‘á»‘i tÆ°á»£ng chÃ­nh vÃ  rÃµ rÃ ng nháº¥t (vÃ­ dá»¥: Mom, Dad, Son, Daughter, Wife, Husband)

2. **Target Audience** (NgÆ°á»i mua - MAX 3 labels):
   - Chá»n nhÃ³m mua hÃ ng chÃ­nh 
   - Pháº£i Cá»¤ THá»‚, khÃ´ng Ä‘Æ°á»£c chung chung nhÆ° "Family Members" hay "Friends"
   - VÃ­ dá»¥ cá»¥ thá»ƒ: "From Daughter", "From Son", "From Husband", "From Wife", "From Mother", "From Father", "From Spouse", "From dog owners", "From beer enthusiasts", "From police officers", "From colleagues", etc.

3. **Usage Purpose** (Má»¥c Ä‘Ã­ch - MAX 3 labels):
   - Má»¥c Ä‘Ã­ch sá»­ dá»¥ng chÃ­nh (Gift, Home Decor, Personal Use, Keepsake, Functional Use)

4. **Occasion** (Dá»‹p - MAX 3 labels):
   - Chá»‰ nhá»¯ng dá»‹p chÃ­nh vÃ  rÃµ rÃ ng nháº¥t
   - Pháº£i Cá»¤ THá»‚: "Mother's Birthday", "Father's Birthday", "Dad's Birthday", "Son's Birthday", "Daughter's Birthday", "Christmas Gift", "Mother's Day", "Father's Day", "Valentine's Day", "Anniversaries", "Pet birthdays", etc.

5. **Niche/Theme** (Chá»§ Ä‘á» - MAX 3 labels):
   - Chá»§ Ä‘á» chÃ­nh cá»§a sáº£n pháº©m (Mother, Father, Police, Beer, Cowgirl, Witch, Pet, Sports, etc.)

6. **Sentiment/Tone** (Cáº£m xÃºc - MAX 3 labels):
   - Cáº£m xÃºc chÃ­nh (Sentimental, Humorous, Elegant, Sophisticated, Playful, Inspirational, etc.)

7. **Message Type** (Loáº¡i thÃ´ng Ä‘iá»‡p - MAX 1 label):
   - Chá»n 1 loáº¡i phÃ¹ há»£p nháº¥t (No quote, Symbolic Message, From-to Signature, Personal Identity)

8. **Personalization Type** (CÃ¡ nhÃ¢n hÃ³a - MAX 1 label):
   - Chá»n loáº¡i cÃ¡ nhÃ¢n hÃ³a chÃ­nh (Personalized Name, Non-personalized, Custom Text, etc.)

9. **Product Type** (Loáº¡i sáº£n pháº©m - MAX 2 labels):
   - Loáº¡i sáº£n pháº©m cá»¥ thá»ƒ (Desk Plaque, Mug, Hoodie, Earrings, Watch, Keychain, Hanging Suncatcher, T-Shirt, etc.)

10. **Placement/Display Context** (Bá»‘i cáº£nh - MAX 2 labels):
    - NÆ¡i trÆ°ng bÃ y chÃ­nh (Shelf decor, Desk decor, Bedroom display, Window decor, Wearable, etc.)

11. **Design Style** (Phong cÃ¡ch - MAX 4 labels):
    - CHÃš Ã: "3D Rendered" chá»‰ khi THIáº¾T Káº¾ in lÃªn sáº£n pháº©m thá»±c sá»± lÃ  3D rendered
    - CÃ¡c phong cÃ¡ch khÃ¡c: Elegant, Vintage, Stained Glass, Floral Motif, Gothic, Minimalist, Abstract, etc.

12. **Color Aesthetic** (MÃ u sáº¯c - MAX 2 labels):
    - MÃ u sáº¯c chá»§ Ä‘áº¡o (Pink, Blue, Gold, Pastel, Black, Purple, Rainbow, Monochrome, etc.)

13. **Trademark Level** (Má»©c Ä‘á»™ thÆ°Æ¡ng hiá»‡u - 1 label):
    - Chá»n 1 má»©c: No TM, Slight TM, TM, TM resemblance

14. **Main Subject** (Chá»§ thá»ƒ chÃ­nh - MAX 2 labels):
    - Äá»‘i tÆ°á»£ng chÃ­nh trong thiáº¿t káº¿ (Rose, Butterfly, Truck, Police Badge, Animal, Text Design, etc.)

15. **Text** (Ná»™i dung vÄƒn báº£n):
    - Ghi chÃ­nh xÃ¡c toÃ n bá»™ vÄƒn báº£n xuáº¥t hiá»‡n trÃªn sáº£n pháº©m
    - Náº¿u khÃ´ng cÃ³ vÄƒn báº£n, ghi "No text"

**OUTPUT FORMAT - Báº®T BUá»˜C PHáº¢I ÄÃšNG Äá»ŠNH Dáº NG JSON:**
```json
{
  "image_recipient": ["value1", "value2"],
  "target_audience": ["value1", "value2"], 
  "usage_purpose": ["value1", "value2", "value3"],
  "occasion": ["value1", "value2"],
  "niche_theme": ["value1", "value2"],
  "sentiment_tone": ["value1", "value2"],
  "message_type": ["value1"],
  "personalization_type": ["value1"],
  "product_type": ["value1", "value2"],
  "placement_display_context": ["value1", "value2"],
  "design_style": ["value1", "value2"],
  "color_aesthetic": ["value1", "value2"],
  "trademark_level": "value",
  "main_subject": ["value1", "value2"],
  "text": ["value1", "value2"]
}
```

HÃ£y phÃ¢n tÃ­ch cáº©n tháº­n vÃ  tráº£ vá» káº¿t quáº£ JSON chÃ­nh xÃ¡c.
"""

    def _download_image(self, url: str) -> bytes:
        """Download image tá»« URL vá»›i retry mechanism"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.get(url, timeout=30, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                response.raise_for_status()
                return response.content
            except Exception as e:
                if attempt == max_retries - 1:
                    raise Exception(f"Lá»—i download áº£nh sau {max_retries} láº§n thá»­: {str(e)}")
                time.sleep(1)

    def _analyze_with_ollama(self, image_url: str) -> Dict:
        """PhÃ¢n tÃ­ch vá»›i GPT OSS 20B - Tá»‘i Æ°u hÃ³a cho model má»›i"""
        try:
            print(f"ğŸ” Äang phÃ¢n tÃ­ch vá»›i {self.ollama_model}...")
            
            # Download vÃ  encode image
            image_bytes = self._download_image(image_url)
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')

            prompt = self._create_labeling_prompt()

            # Cáº¥u hÃ¬nh tá»‘i Æ°u cho GPT OSS 20B (model lá»›n hÆ¡n, cáº§n parameters khÃ¡c)
            response = ollama.generate(
                model=self.ollama_model,
                prompt=prompt,
                images=[image_base64],
                options={
                    'temperature': 0.05,  # Giáº£m temperature cho káº¿t quáº£ á»•n Ä‘á»‹nh
                    'top_p': 0.85,       # Tá»‘i Æ°u cho model lá»›n
                    'num_ctx': 12288,    # Context length lá»›n hÆ¡n cho GPT OSS 20B
                    'repeat_penalty': 1.05,  # Giáº£m repeat penalty
                    'num_predict': 3072, # TÄƒng prediction tokens
                    'top_k': 30,        # ThÃªm top_k constraint
                    'seed': 42          # Fixed seed Ä‘á»ƒ reproducible
                }
            )

            content = response['response']
            
            # Parse JSON response vá»›i error handling tá»‘t hÆ¡n
            json_start = content.find('{')
            json_end = content.rfind('}') + 1

            if json_start != -1 and json_end != -1:
                json_str = content[json_start:json_end]
                try:
                    result = json.loads(json_str)
                    print(f"âœ… {self.ollama_model} phÃ¢n tÃ­ch thÃ nh cÃ´ng")
                    return result
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  Lá»—i parse JSON tá»« {self.ollama_model}: {str(e)}")
                    print(f"Raw response: {content[:500]}...")
                    raise Exception(f"Invalid JSON response from {self.ollama_model}")
            else:
                raise Exception(f"KhÃ´ng tÃ¬m tháº¥y JSON trong response tá»« {self.ollama_model}")

        except Exception as e:
            raise Exception(f"Lá»—i {self.ollama_model} analysis: {str(e)}")

    def _analyze_with_google(self, image_url: str) -> Dict:
        """PhÃ¢n tÃ­ch vá»›i Google Gemini"""
        if not self.google_client:
            raise Exception("Google client chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")

        try:
            print("ğŸ” Äang phÃ¢n tÃ­ch vá»›i Google Gemini...")
            
            image_bytes = self._download_image(image_url)
            image = Image.open(BytesIO(image_bytes))
            prompt = self._create_labeling_prompt()

            response = self.google_client.generate_content([prompt, image])
            content = response.text

            json_start = content.find('{')
            json_end = content.rfind('}') + 1

            if json_start != -1 and json_end != -1:
                json_str = content[json_start:json_end]
                result = json.loads(json_str)
                print("âœ… Google Gemini phÃ¢n tÃ­ch thÃ nh cÃ´ng")
                return result
            else:
                raise Exception("KhÃ´ng tÃ¬m tháº¥y JSON trong response tá»« Google")

        except Exception as e:
            raise Exception(f"Lá»—i Google analysis: {str(e)}")

    def _merge_results(self, ollama_result: Dict, google_result: Dict) -> Dict:
        """Káº¿t há»£p káº¿t quáº£ tá»« 2 model vá»›i logic thÃ´ng minh hÆ¡n"""
        merged = {}
        all_keys = set(ollama_result.keys()) | set(google_result.keys())

        for key in all_keys:
            ollama_values = ollama_result.get(key, [])
            google_values = google_result.get(key, [])

            if isinstance(ollama_values, list) and isinstance(google_values, list):
                # Káº¿t há»£p vÃ  loáº¡i bá» duplicate, Æ°u tiÃªn GPT OSS 20B
                combined = ollama_values + [v for v in google_values if v not in ollama_values]
                merged[key] = combined[:4]  # Limit to max 4 items
            elif isinstance(ollama_values, str) and isinstance(google_values, str):
                # Æ¯u tiÃªn GPT OSS 20B cho string values
                merged[key] = ollama_values if ollama_values else google_values
            else:
                merged[key] = ollama_values if ollama_values else google_values

        return merged

    def label_image(self, image_url: str, provider: ModelProvider = ModelProvider.OLLAMA) -> ProductLabel:
        """ÄÃ¡nh label cho 1 áº£nh sáº£n pháº©m - Máº·c Ä‘á»‹nh dÃ¹ng GPT OSS 20B"""
        try:
            if provider == ModelProvider.OLLAMA:
                result = self._analyze_with_ollama(image_url)
            elif provider == ModelProvider.GOOGLE:
                result = self._analyze_with_google(image_url)
            else:  # BOTH
                try:
                    ollama_result = self._analyze_with_ollama(image_url)
                except Exception as e:
                    print(f"âš ï¸  GPT OSS 20B failed, fallback to Google: {str(e)}")
                    result = self._analyze_with_google(image_url)
                else:
                    try:
                        google_result = self._analyze_with_google(image_url)
                        result = self._merge_results(ollama_result, google_result)
                    except Exception as e:
                        print(f"âš ï¸  Google failed, using GPT OSS 20B only: {str(e)}")
                        result = ollama_result

            return ProductLabel(
                image_url=image_url,
                image_recipient=result.get('image_recipient', []),
                target_audience=result.get('target_audience', []),
                usage_purpose=result.get('usage_purpose', []),
                occasion=result.get('occasion', []),
                niche_theme=result.get('niche_theme', []),
                sentiment_tone=result.get('sentiment_tone', []),
                message_type=result.get('message_type', []),
                personalization_type=result.get('personalization_type', []),
                product_type=result.get('product_type', []),
                placement_display_context=result.get('placement_display_context', []),
                design_style=result.get('design_style', []),
                color_aesthetic=result.get('color_aesthetic', []),
                trademark_level=result.get('trademark_level', 'No TM'),
                main_subject=result.get('main_subject', []),
                text=result.get('text', [])
            )

        except Exception as e:
            raise Exception(f"Lá»—i labeling: {str(e)}")

    # === VECTOR GENERATION METHODS ===
    def _generate_vectors(self, text: str, image_url: str = None) -> tuple:
        """
        Táº¡o embedding vectors cho text vÃ  image sá»­ dá»¥ng Jina v4

        Args:
            text: Text description Ä‘á»ƒ embedding
            image_url: URL cá»§a image Ä‘á»ƒ embedding

        Returns:
            tuple: (image_vector, text_vector)
        """
        # Sá»­ dá»¥ng method tá»« EmbeddingService
        image_vector, text_vector = self.embedding_service._generate_vectors(
            text=text,
            image_url=image_url
        )

        print(f"âœ… Táº¡o embedding thÃ nh cÃ´ng - Text: {len(text_vector)}D, Image: {len(image_vector)}D")
        return image_vector, text_vector

    def _generate_vectors_batch(self, descriptions: List[str], image_urls: List[str] = None) -> tuple:
        """
        Táº¡o embedding vectors cho nhiá»u text vÃ  image cÃ¹ng lÃºc (hiá»‡u quáº£ hÆ¡n)

        Args:
            descriptions: List text descriptions
            image_urls: List image URLs (optional)

        Returns:
            tuple: (image_vectors_list, text_vectors_list)
        """
        # Batch embedding cho text
        text_vectors = self.embedding_service.embed_texts_batch(
            descriptions,
            normalize=True,
            batch_size=32
        )

        # Batch embedding cho images (náº¿u cÃ³)
        image_vectors = []
        if image_urls:
            for image_url in image_urls:
                if image_url and image_url.strip():
                    img_vec = self.embedding_service.embed_image(image_url, normalize=True)
                else:
                    img_vec = [0.0] * self.embedding_dim
                image_vectors.append(img_vec)
        else:
            image_vectors = [[0.0] * self.embedding_dim] * len(descriptions)

        print(f"âœ… Táº¡o batch embedding thÃ nh cÃ´ng - {len(descriptions)} records")
        return image_vectors, text_vectors

    def _create_description(self, label: ProductLabel) -> str:
        """Táº¡o description dáº¡ng markdown tá»« ProductLabel"""

        def format_list(items: List[str]) -> str:
            if not items:
                return "KhÃ´ng xÃ¡c Ä‘á»‹nh"
            return ", ".join(items)

        description = f"""# MÃ´ Táº£ Sáº£n Pháº©m

## ThÃ´ng Tin CÆ¡ Báº£n
- **Chá»§ Thá»ƒ ChÃ­nh**: {format_list(label.main_subject)}
- **Loáº¡i Sáº£n Pháº©m**: {format_list(label.product_type)}
- **Má»©c Äá»™ ThÆ°Æ¡ng Hiá»‡u**: {label.trademark_level}

## Äá»‘i TÆ°á»£ng & Má»¥c ÄÃ­ch
- **NgÆ°á»i Nháº­n**: {format_list(label.image_recipient)}
- **NgÆ°á»i Mua**: {format_list(label.target_audience)}
- **Má»¥c ÄÃ­ch Sá»­ Dá»¥ng**: {format_list(label.usage_purpose)}
- **Dá»‹p Sá»­ Dá»¥ng**: {format_list(label.occasion)}

## PhÃ¢n Loáº¡i Sáº£n Pháº©m
- **Chá»§ Äá»/NgÃ¡ch**: {format_list(label.niche_theme)}
- **Cáº£m XÃºc/TÃ´ng Äiá»‡u**: {format_list(label.sentiment_tone)}
- **Loáº¡i ThÃ´ng Äiá»‡p**: {format_list(label.message_type)}
- **CÃ¡ NhÃ¢n HÃ³a**: {format_list(label.personalization_type)}
- **Ná»™i Dung Chá»¯ In**: {format_list(label.text)}

## Thiáº¿t Káº¿ & TrÆ°ng BÃ y
- **Bá»‘i Cáº£nh TrÆ°ng BÃ y**: {format_list(label.placement_display_context)}
- **Phong CÃ¡ch Thiáº¿t Káº¿**: {format_list(label.design_style)}
- **Tháº©m Má»¹ MÃ u Sáº¯c**: {format_list(label.color_aesthetic)}

## TÃ³m Táº¯t
{format_list(label.product_type)} nÃ y lÃ  má»™t {format_list(label.main_subject)} Ä‘Æ°á»£c thiáº¿t káº¿ dÃ nh cho {format_list(label.image_recipient)}, phÃ¹ há»£p cho {format_list(label.occasion)} vá»›i phong cÃ¡ch {format_list(label.design_style)} vÃ  tÃ´ng mÃ u {format_list(label.color_aesthetic)}.
"""
        return description

    # === MAIN PROCESSING METHODS ===
    def process_single_record(self, raw_data: Dict[str, Any],
                              provider: ModelProvider = ModelProvider.OLLAMA) -> ProductRecord:
        """
        Xá»­ lÃ½ 1 record: raw data â†’ label â†’ vectors â†’ ProductRecord

        Args:
            raw_data: Data thÃ´ tá»« database
            provider: Model provider Ä‘á»ƒ labeling

        Returns:
            ProductRecord sáºµn sÃ ng Ä‘á»ƒ insert vÃ o Milvus
        """
        try:
            image_url = raw_data.get('image', '')
            if not image_url:
                raise Exception("KhÃ´ng cÃ³ URL áº£nh")

            # 1. Label metadata
            label = self.label_image(image_url, provider)
            metadata = asdict(label)

            # 2. Táº¡o description markdown
            description = self._create_description(label)

            # 3. Táº¡o embedding vectors báº±ng Sentence Transformers
            image_vector, description_vector = self._generate_vectors(description, image_url)

            # 4. Táº¡o ProductRecord
            record = ProductRecord(
                id_sanpham=raw_data.get('id_sanpham', f"SP_{uuid.uuid4().hex[:8]}"),
                image_vector=image_vector,
                description_vector=description_vector,
                image=image_url,
                description=description,
                metadata=metadata,
                date=raw_data.get('date', ''),
                like=raw_data.get('like', '0'),
                comment=raw_data.get('comment', '0'),
                share=raw_data.get('share', '0'),
                link_redirect=raw_data.get('link_redirect', ''),
                platform=raw_data.get('platform', ''),
                name_store=raw_data.get('name_store', '')
            )

            return record

        except Exception as e:
            raise Exception(f"Lá»—i xá»­ lÃ½ record {raw_data.get('id_sanpham', 'unknown')}: {str(e)}")

    def process_batch_records(self, raw_data_list: List[Dict[str, Any]],
                              provider: ModelProvider = ModelProvider.OLLAMA) -> List[ProductRecord]:
        """
        Xá»­ lÃ½ nhiá»u records cÃ¹ng lÃºc Ä‘á»ƒ tá»‘i Æ°u batch embedding

        Args:
            raw_data_list: List data thÃ´ tá»« database
            provider: Model provider Ä‘á»ƒ labeling

        Returns:
            List ProductRecord sáºµn sÃ ng Ä‘á»ƒ insert vÃ o Milvus
        """
        try:
            # Chuáº©n bá»‹ data cho batch processing
            records = []
            descriptions = []
            image_urls = []

            # Táº¡o labels vÃ  descriptions cho táº¥t cáº£ records
            for raw_data in raw_data_list:
                try:
                    image_url = raw_data.get('image', '')
                    if not image_url:
                        continue

                    # Label metadata
                    label = self.label_image(image_url, provider)
                    metadata = asdict(label)

                    # Táº¡o description
                    description = self._create_description(label)

                    # Táº¡o record template (chÆ°a cÃ³ vectors)
                    record = ProductRecord(
                        id_sanpham=raw_data.get('id_sanpham', f"SP_{uuid.uuid4().hex[:8]}"),
                        image_vector=[],  # Sáº½ Ä‘Æ°á»£c fill sau
                        description_vector=[],  # Sáº½ Ä‘Æ°á»£c fill sau
                        image=image_url,
                        description=description,
                        metadata=metadata,
                        date=raw_data.get('date', ''),
                        like=raw_data.get('like', '0'),
                        comment=raw_data.get('comment', '0'),
                        share=raw_data.get('share', '0'),
                        link_redirect=raw_data.get('link_redirect', ''),
                        platform=raw_data.get('platform', ''),
                        name_store=raw_data.get('name_store', '')
                    )

                    records.append(record)
                    descriptions.append(description)
                    image_urls.append(image_url)

                except Exception as e:
                    print(f"Lá»—i xá»­ lÃ½ record {raw_data.get('id_sanpham', 'unknown')}: {str(e)}")
                    continue

            if not records:
                return []

            # Batch embedding cho táº¥t cáº£ descriptions vÃ  images
            print(f"ğŸ”„ Báº¯t Ä‘áº§u batch embedding cho {len(records)} records...")
            image_vectors, text_vectors = self._generate_vectors_batch(descriptions, image_urls)

            # GÃ¡n vectors vÃ o records
            for i, record in enumerate(records):
                record.image_vector = image_vectors[i]
                record.description_vector = text_vectors[i]

            print(f"âœ… HoÃ n thÃ nh batch processing {len(records)} records")
            return records

        except Exception as e:
            print(f"âŒ Lá»—i batch processing: {str(e)}")
            return []

    def insert_record(self, record: ProductRecord) -> str:
        """
        Insert 1 ProductRecord vÃ o Milvus

        Args:
            record: ProductRecord Ä‘á»ƒ insert

        Returns:
            ID cá»§a record Ä‘Ã£ insert
        """
        try:
            data = [
                [record.id_sanpham],
                [record.image_vector],
                [record.description_vector],
                [record.image],
                [record.description],
                [record.metadata],
                [record.date],
                [record.like],
                [record.comment],
                [record.share],
                [record.link_redirect],
                [record.platform],
                [record.name_store]
            ]

            mr = self.collection.insert(data)
            self.collection.flush()

            return record.id_sanpham

        except Exception as e:
            raise Exception(f"Lá»—i insert record {record.id_sanpham}: {str(e)}")

    def insert_batch_records(self, records: List[ProductRecord]) -> List[str]:
        """
        Insert nhiá»u ProductRecord vÃ o Milvus cÃ¹ng lÃºc (hiá»‡u quáº£ hÆ¡n)

        Args:
            records: List ProductRecord Ä‘á»ƒ insert

        Returns:
            List ID cá»§a cÃ¡c record Ä‘Ã£ insert
        """
        try:
            if not records:
                return []

            # Chuáº©n bá»‹ data cho batch insert
            ids = [record.id_sanpham for record in records]
            image_vectors = [record.image_vector for record in records]
            description_vectors = [record.description_vector for record in records]
            images = [record.image for record in records]
            descriptions = [record.description for record in records]
            metadatas = [record.metadata for record in records]
            dates = [record.date for record in records]
            likes = [record.like for record in records]
            comments = [record.comment for record in records]
            shares = [record.share for record in records]
            link_redirects = [record.link_redirect for record in records]
            platforms = [record.platform for record in records]
            name_stores = [record.name_store for record in records]

            data = [
                ids,
                image_vectors,
                description_vectors,
                images,
                descriptions,
                metadatas,
                dates,
                likes,
                comments,
                shares,
                link_redirects,
                platforms,
                name_stores
            ]

            mr = self.collection.insert(data)
            self.collection.flush()

            print(f"âœ… Batch insert thÃ nh cÃ´ng {len(records)} records")
            return ids

        except Exception as e:
            raise Exception(f"Lá»—i batch insert: {str(e)}")

    def run_pipeline(self, start_date: str, end_date: str,
                     limit: int = 1000,
                     provider: ModelProvider = ModelProvider.OLLAMA,
                     batch_size: int = 10) -> Dict[str, Any]:
        """
        Cháº¡y pipeline hoÃ n chá»‰nh: Crawl â†’ Check Duplicates â†’ Label â†’ Insert

        Args:
            start_date: NgÃ y báº¯t Ä‘áº§u (YYYY-MM-DD)
            end_date: NgÃ y káº¿t thÃºc (YYYY-MM-DD)
            limit: Sá»‘ lÆ°á»£ng record tá»‘i Ä‘a
            provider: Model provider Ä‘á»ƒ labeling (máº·c Ä‘á»‹nh GPT OSS 20B)
            batch_size: Sá»‘ record xá»­ lÃ½ má»—i batch

        Returns:
            Dictionary chá»©a thá»‘ng kÃª káº¿t quáº£
        """
        print("ğŸš€ Báº®T Äáº¦U PIPELINE TÃCH Há»¢P Vá»šI GPT OSS 20B")
        print(f"ğŸ“… Thá»i gian: {start_date} â†’ {end_date}")
        print(f"ğŸ“Š Giá»›i háº¡n: {limit} records")
        print(f"ğŸ¤– Provider: {provider.value}")
        print(f"ğŸ¦¾ Ollama Model: {self.ollama_model}")
        print("-" * 80)

        start_time = time.time()

        # Statistics
        stats = {
            'start_time': datetime.now().isoformat(),
            'ollama_model': self.ollama_model,
            'crawled_count': 0,
            'duplicate_count': 0,
            'processed_count': 0,
            'inserted_count': 0,
            'failed_count': 0,
            'skipped_duplicates': [],
            'inserted_ids': [],
            'failed_records': [],
            'total_time_seconds': 0
        }

        try:
            # STEP 1: Crawl data tá»« database
            print("ğŸ“¥ STEP 1: Crawl data tá»« database...")
            raw_data_list = self.crawl_data_by_date_range(start_date, end_date, limit)

            if not raw_data_list:
                print("âš ï¸  KhÃ´ng cÃ³ data Ä‘á»ƒ xá»­ lÃ½")
                return stats

            stats['crawled_count'] = len(raw_data_list)
            print(f"âœ… Crawl Ä‘Æ°á»£c {len(raw_data_list)} records")

            # STEP 2: Check duplicates vÃ  lá»c bá»
            print("ğŸ” STEP 2: Kiá»ƒm tra vÃ  lá»c bá» records trÃ¹ng láº·p...")
            new_records, existing_records, duplicate_count = self.filter_existing_records(raw_data_list)

            stats['duplicate_count'] = duplicate_count
            stats['skipped_duplicates'] = [record.get('id_sanpham', 'unknown') for record in existing_records]

            if not new_records:
                print("âš ï¸  Táº¥t cáº£ records Ä‘Ã£ tá»“n táº¡i trong Milvus, khÃ´ng cÃ³ gÃ¬ Ä‘á»ƒ xá»­ lÃ½")
                return stats

            print(f"âœ… Sáº½ xá»­ lÃ½ {len(new_records)} records má»›i vá»›i {self.ollama_model}")

            # STEP 3: Process tá»«ng record vá»›i batch
            print(f"ğŸ”„ STEP 3: Xá»­ lÃ½ {len(new_records)} records má»›i vá»›i batch_size={batch_size}")

            for i in range(0, len(new_records), batch_size):
                batch = new_records[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                total_batches = (len(new_records) + batch_size - 1) // batch_size

                print(f"ğŸ“¦ Batch {batch_num}/{total_batches}: Xá»­ lÃ½ {len(batch)} records")

                for j, raw_data in enumerate(batch):
                    record_idx = i + j + 1

                    try:
                        print(f"  ğŸ” [{record_idx}/{len(new_records)}] Xá»­ lÃ½: {raw_data.get('id_sanpham', 'unknown')}")

                        # Process single record: label + vector
                        record = self.process_single_record(raw_data, provider)
                        stats['processed_count'] += 1

                        # Insert vÃ o Milvus
                        inserted_id = self.insert_record(record)
                        stats['inserted_count'] += 1
                        stats['inserted_ids'].append(inserted_id)

                        print(f"  âœ… [{record_idx}/{len(new_records)}] ThÃ nh cÃ´ng: {inserted_id}")

                        # Delay nhá» Ä‘á»ƒ trÃ¡nh rate limit
                        time.sleep(0.5)

                    except Exception as e:
                        stats['failed_count'] += 1
                        error_info = {
                            'id_sanpham': raw_data.get('id_sanpham', 'unknown'),
                            'image_url': raw_data.get('image', ''),
                            'error': str(e)
                        }
                        stats['failed_records'].append(error_info)
                        print(f"  âŒ [{record_idx}/{len(new_records)}] Lá»—i: {str(e)}")
                        continue

                # Log batch progress
                print(f"ğŸ“¦ Batch {batch_num}/{total_batches} hoÃ n thÃ nh")
                print(f"   âœ… ThÃ nh cÃ´ng: {stats['processed_count']}/{len(new_records)}")
                print(f"   âŒ Tháº¥t báº¡i: {stats['failed_count']}/{len(new_records)}")

        except Exception as e:
            print(f"âŒ Lá»—i nghiÃªm trá»ng trong pipeline: {str(e)}")

        finally:
            # TÃ­nh toÃ¡n thá»i gian
            end_time = time.time()
            stats['total_time_seconds'] = round(end_time - start_time, 2)
            stats['end_time'] = datetime.now().isoformat()

            # Log káº¿t quáº£ cuá»‘i cÃ¹ng
            print("=" * 80)
            print("ğŸŠ PIPELINE HOÃ€N THÃ€NH!")
            print(f"ğŸ“Š THá»NG KÃŠ Tá»”NG Káº¾T:")
            print(f"   ğŸ¦¾ Model sá»­ dá»¥ng: {self.ollama_model}")
            print(f"   ğŸ“¥ Crawl: {stats['crawled_count']} records")
            print(f"   ğŸ”„ TrÃ¹ng láº·p (bá» qua): {stats['duplicate_count']} records")
            print(f"   ğŸ†• Records má»›i: {len(new_records) if 'new_records' in locals() else 0} records")
            print(f"   ğŸ”„ Xá»­ lÃ½: {stats['processed_count']} records")
            print(f"   âœ… Insert thÃ nh cÃ´ng: {stats['inserted_count']} records")
            print(f"   âŒ Tháº¥t báº¡i: {stats['failed_count']} records")
            print(f"   â±ï¸  Tá»•ng thá»i gian: {stats['total_time_seconds']}s")

            # TÃ­nh tá»‰ lá»‡ thÃ nh cÃ´ng trÃªn records má»›i (khÃ´ng tÃ­nh trÃ¹ng láº·p)
            new_records_count = len(new_records) if 'new_records' in locals() else max(
                stats['crawled_count'] - stats['duplicate_count'], 1)
            success_rate = stats['inserted_count'] / max(new_records_count, 1) * 100
            print(f"   ğŸ“ˆ Tá»‰ lá»‡ thÃ nh cÃ´ng: {success_rate:.1f}%")

            # Hiá»ƒn thá»‹ collection stats
            try:
                total_entities = self.collection.num_entities
                print(f"   ğŸ’¾ Tá»•ng entities trong Milvus: {total_entities}")
            except:
                pass

            print("=" * 80)

            return stats

    def search_similar_products(self, query_vector: List[float],
                                field_name: str = "image_vector",
                                top_k: int = 5):
        """
        TÃ¬m kiáº¿m sáº£n pháº©m tÆ°Æ¡ng tá»±

        Args:
            query_vector: Vector Ä‘á»ƒ search
            field_name: Field vector Ä‘á»ƒ search ("image_vector" hoáº·c "description_vector")
            top_k: Sá»‘ káº¿t quáº£ tráº£ vá»
        """
        search_params = {
            "metric_type": "COSINE",
            "params": {"nprobe": 10}
        }

        results = self.collection.search(
            data=[query_vector],
            anns_field=field_name,
            param=search_params,
            limit=top_k,
            output_fields=["id_sanpham", "image", "platform", "metadata"]
        )

        return results

    def save_stats_to_json(self, stats: Dict[str, Any], filename: str = None):
        """LÆ°u thá»‘ng kÃª vÃ o file JSON"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"pipeline_stats_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ÄÃ£ lÆ°u thá»‘ng kÃª vÃ o: {filename}")
        except Exception as e:
            print(f"âŒ Lá»—i lÆ°u file: {e}")

    def close_connections(self):
        """ÄÃ³ng táº¥t cáº£ káº¿t ná»‘i"""
        try:
            if self.db_connection:
                self.db_connection.close()
                print("âœ… ÄÃ£ Ä‘Ã³ng káº¿t ná»‘i PostgreSQL")
        except:
            pass


def main():
    """
    HÃ m main Ä‘Æ°á»£c cáº­p nháº­t cho GPT OSS 20B
    """
    print("ğŸš€ KHá»I Äá»˜NG INTEGRATED PRODUCT PIPELINE - GPT OSS 20B + GOOGLE")
    print("=" * 60)

    # ========== CONFIGURATION ==========
    # Database config
    db_config = {
        'host': '45.79.189.110',
        'database': 'ai_db',
        'user': 'ai_engineer',
        'password': 'StrongPassword123',
        'port': 5432
    }

    # API Keys
    google_api_key = "AIzaSyC0-LkawNpB_krGzPmR6fe7zpFyk476LGY"

    # Ollama config - Updated to GPT OSS 20B
    ollama_model = "gpt-oss:20b"  # Model má»›i Ä‘Æ°á»£c cáº­p nháº­t

    # Milvus config
    milvus_host = "10.10.4.25"
    milvus_port = "19530"

    # ========== THá»œI GIAN CRAWL ==========
    start_date = "2025-07-01"  # YYYY-MM-DD
    end_date = "2025-08-14"   # YYYY-MM-DD

    # ========== CÃ€I Äáº¶T PIPELINE ==========
    limit = 5000  # Giá»›i háº¡n sá»‘ record Ä‘á»ƒ test
    provider = ModelProvider.OLLAMA  # Máº·c Ä‘á»‹nh dÃ¹ng GPT OSS 20B
    batch_size = 10  # Sá»‘ record xá»­ lÃ½ má»—i batch

    try:
        # Khá»Ÿi táº¡o pipeline
        print("ğŸ”§ Khá»Ÿi táº¡o pipeline...")
        pipeline = IntegratedProductPipeline(
            db_config=db_config,
            google_api_key=google_api_key,
            ollama_model=ollama_model,
            milvus_host=milvus_host,
            milvus_port=milvus_port
        )

        print("âœ… Pipeline khá»Ÿi táº¡o thÃ nh cÃ´ng!")

        # Cháº¡y pipeline chÃ­nh
        print(f"ğŸ¯ Báº¯t Ä‘áº§u crawl data tá»« {start_date} Ä‘áº¿n {end_date}")

        stats = pipeline.run_pipeline(
            start_date=start_date,
            end_date=end_date,
            limit=limit,
            provider=provider,
            batch_size=batch_size
        )

        # LÆ°u thá»‘ng kÃª
        pipeline.save_stats_to_json(stats)

        # Hiá»ƒn thá»‹ káº¿t quáº£ ngáº¯n gá»n
        print("\nğŸŠ Káº¾T QUáº¢ CUá»I CÃ™NG:")
        print(f"ğŸ¦¾ Model: {stats.get('ollama_model', 'N/A')}")
        print(f"âœ… ThÃ nh cÃ´ng: {stats['inserted_count']}/{stats['crawled_count']} records")
        print(f"ğŸ”„ TrÃ¹ng láº·p (bá» qua): {stats['duplicate_count']} records")
        print(f"â±ï¸  Thá»i gian: {stats['total_time_seconds']}s")

        if stats['inserted_ids']:
            print(f"ğŸ“¦ Má»™t sá»‘ ID Ä‘Ã£ insert:")
            for i, record_id in enumerate(stats['inserted_ids'][:5]):
                print(f"   {i + 1}. {record_id}")
            if len(stats['inserted_ids']) > 5:
                print(f"   ... vÃ  {len(stats['inserted_ids']) - 5} records khÃ¡c")

        if stats['skipped_duplicates']:
            print(f"ğŸ”„ Má»™t sá»‘ ID trÃ¹ng láº·p (Ä‘Ã£ bá» qua):")
            for i, record_id in enumerate(stats['skipped_duplicates'][:5]):
                print(f"   {i + 1}. {record_id}")
            if len(stats['skipped_duplicates']) > 5:
                print(f"   ... vÃ  {len(stats['skipped_duplicates']) - 5} records khÃ¡c")

    except Exception as e:
        print(f"âŒ Lá»–I NGHIÃŠM TRá»ŒNG: {str(e)}")

    finally:
        try:
            pipeline.close_connections()
        except:
            pass

        print("\nğŸ‘‹ Pipeline káº¿t thÃºc!")


if __name__ == "__main__":
    main()